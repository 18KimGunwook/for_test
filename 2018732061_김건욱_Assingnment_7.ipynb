{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNsSWswKhP2qQFu31vwGeUw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Assingnment 7\n","\n","* 행렬 방정식 풀기  \n","  + 다음 행렬 방정식을 'Linear Regression'을 이용해 풀어보자\n","  + 적당한 learning rate를 찾아 1000 epoch 정도 계산해본다\n","* 'Pseudo Inverse'를 이용한 풀이와 비교해본다\n","  + Hint: y = wx 꼴로 변환해본다\n","  + Ax=B에서는 x가 미지수이지만, y=wx에서는 w가 미지수임에 주의!  \n","linear model에서 b를 없애기 위해서 nn.Linear() 사용법을 검색해보자  \n","\n","$$Ax=B$$  \n","$$A=\\begin{bmatrix}0&1\\\\1&1\\\\2&1\\\\3&1\\\\ \\end{bmatrix}$$  \n","$$B=\\begin{bmatrix}-1\\\\0.2\\\\0.9\\\\2.1\\\\ \\end{bmatrix}$$\n"],"metadata":{"id":"yk8R07DanWmE"}},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wveKFzEA9jS6","executionInfo":{"status":"ok","timestamp":1697445801305,"user_tz":-540,"elapsed":628,"user":{"displayName":"김건욱","userId":"05793746430241416204"}},"outputId":"cd80b7d6-eb09-4260-e067-9746f2f5cf4f"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Parameter containing:\n","tensor([[ 0.3643, -0.3121]], requires_grad=True)]\n","Epoch  100/1000 Cost: 0.013041\n","Epoch  200/1000 Cost: 0.012501\n","Epoch  300/1000 Cost: 0.012500\n","Epoch  400/1000 Cost: 0.012500\n","Epoch  500/1000 Cost: 0.012500\n","Epoch  600/1000 Cost: 0.012500\n","Epoch  700/1000 Cost: 0.012500\n","Epoch  800/1000 Cost: 0.012500\n","Epoch  900/1000 Cost: 0.012500\n","Epoch 1000/1000 Cost: 0.012500\n","Linear Regression을 사용한 결과 =\n","[Parameter containing:\n","tensor([[ 1.0000, -0.9500]], requires_grad=True)]\n","Pseudo Inverse을 사용한 결과 =\n","[[ 1.       ]\n"," [-0.9500001]]\n"]}],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as func\n","import torch.optim as opt\n","\n","# Seed 고정\n","torch.manual_seed(1)\n","\n","x_train = torch.FloatTensor([[0, 1],[1, 1],[2, 1],[3,1]])\n","y_train = torch.FloatTensor([[-1],[0.2],[0.9],[2.1]])\n","\n","# Linear model\n","#bias를 없에기 위해 bias=False 을 추가한다.\n","model = nn.Linear(2,1,bias=False)\n","\n","print(list(model.parameters()))\n","\n","# Optimizer 설정\n","# learning rate는 적절한 값인 0.05로 정한다.\n","optimizer = opt.SGD(model.parameters(), lr=0.05)\n","\n","# 1000번 반복하며 cost를 줄인다.\n","for epoch in range(1000):\n","  y_hypo = model(x_train)\n","  cost = func.mse_loss(y_hypo, y_train)\n","\n","  # model update\n","  optimizer.zero_grad()\n","  cost.backward()\n","  optimizer.step()\n","\n","  # 100번 마다 중간결과 출력\n","  if epoch % 100 == 99:\n","    print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch+1, 1000, cost.item()))\n","\n","# weight를 출력한다.\n","print('Linear Regression을 사용한 결과 =')\n","print(list(model.parameters()))\n","\n","#Pseudo Inverse를 이용한 풀이와 비교해본다\n","A_mat=torch.FloatTensor([[0, 1],[1, 1],[2, 1],[3, 1]])\n","B_mat=torch.FloatTensor([[-1],[0.2],[0.9],[2.1]])\n","pseudo_inv_A_mat=torch.matmul(torch.inverse(torch.matmul(A_mat.T,A_mat)),A_mat.T)\n","x_mat=np.dot(pseudo_inv_A_mat,B_mat)\n","print('Pseudo Inverse을 사용한 결과 =')\n","print(x_mat)\n","\n","#두 풀이방식의 결과가 같음을 볼 수 있다."]}]}