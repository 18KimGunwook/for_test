{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2018732061_김건욱_실험(4)_예비레포트.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNFPH8E3rw1XXRZ59NhMLOB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#실험 4 예비보고서\n","\n","***\n","###1. 실험제목\n","#### Logistic Regression\n","###2.개요  \n","Logistic Regression에 대해 이론을 숙지하고 model을 세운다.  \n","Binary Cross Entropy를 cost fuction로 하여 model update를 실행 한다.\n","\n","###3.이론  \n","####Logistic Regression(로지스틱 회귀)\n","Logistic Regression란 일종의 확률 모델로서 종속 변수와 독립 변수의 관계를 함수로 나타내어 다음의 변수를 예측하는 것이다. 이는 linear regression(선형 회귀) 함수로 변수들의 관계를 설명 한다는 관점에서는 유사하나, Logistic Regression에서는 데이터들이 특정 분류로 나뉘어 진다.  \n","따라서 0,1, 로만 데이터들을 분류하여 나타내게 되면 다음의 함수를 만족하게 된다.\n","\n","![image.png](https://ifh.cc/g/9DQGjv.png)\n","\n","하지만 이 경우에서는 함수를 미분하지 못하며 특정 변수에서는 값을 여러개를 가져 함수로 정의 되지 못하고, cost 또한 비효율 적이기에 다음의 함수로 타협하게 된다.  \n","![image.png](https://ifh.cc/g/b9V17c.jpg)  \n","이 함수를 Sigmoid라 하며 수식은 다음과 같다.  \n","$$\n","\\begin{aligned}\n","y_{hypo}=H(x)=\\frac{1}{1+e^{-ax}}\n","\\end{aligned}\n","$$ \n","이는 markdown에서 `nn.Sigmoid()` 함수를 통해 모델을 세울 수 있다.  \n","하지만 input 여러개일 경우에는 수식이 다음과 같이 변화한다.\n","$$\n","\\begin{aligned}\n","y_{hypo}=H(x)=\\frac{1}{1+e^{-W^{T}X}}\n","\\end{aligned}\n","$$ \n","따라서 저번 시간에 사용한'nn.Linear()'함수를 통해 W를 1차원으로 만들어 다음과 같이 사용한다. 'nn.Sigmoid(nn.Linear())'  \n","\n","####Binary Cross Entropy  \n","위의 Sigmoide의 오차를 계산하기 위해 cost fuction을 설정해야 하나, 기존의 사용되었던 MSE를 사용할 경우 local minimum이 다수 발생해 gradient descent 사용에 애로가 생기게 된다.  \n","따라서 Binary Cross Entropy 란 함수를 cost로 사용하며 수식은 다음과 같다.\n","$$\n","\\begin{aligned}\n","-[y_{train}log(y_{hypo})+(1-y_{train})log(1-y_{train})]\n","\\end{aligned}\n","$$ \n","이 함수는 미분이 가능하다는 장점을 가지며, markdown에서는 `func.binary_cross_entropy( , )`을 통해 사용한다.\n","\n","####prediction  \n","위의 Sigmoid 및 Binary Cross Entropy를 사용해 gradient descent를 실행하게 된다.\n","하지만 Sigmoid의 함수의 특성상 최종 결과의 값의 cost가 0이 될 수는 없다. 따라서 결과가 특정 값(본 실습에서는 0.5)을 넘기는지 아닌지를 논리연산 하여 최종 판단하는 과정을 prediction이라 한다. 본 실습에서는 이 prediction이 맞는지 아닌지를 확인하여 accuracy를 계산해 결과의 정확도를 나타내는 하나의 척도로 삼는다.  \n","\n","###4.참조  \n","\n","Cox, DR (1958). “The regression analysis of binary sequences (with discussion)”. 《J Roy Stat Soc B》 20: 215–242.  \n","정승기 교수님의 강의노트, 강의영상  \n","이미지 참조(정승기 교수님 강의영상)"],"metadata":{"id":"Eexw5yeeQzWl"}}]}